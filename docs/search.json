[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prateek ShuklaDocumentation for fastAI course.",
    "section": "",
    "text": "Lesson 1: Vision models and Fundamentals\n\n\n\n\n\n\ncomputer_usage\n\n\n\nDocumentation for lesson 1 of fastAI practical deep learning for coders.\n\n\n\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHow to setup WSL and Python for fastAI\n\n\n\n\n\n\ncomputer_usage\n\n\n\nGuide to install dependencies for fastAI.\n\n\n\n\n\nNov 13, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "",
    "text": "The evolution of Machine Learning has transformed from a concept once deemed nearly impossible to a technology that is now easily accessible and widely utilized. It was considered so ridiculous in the early days that people joked about it. Here is one example:\nAbove is an xkcd comic which shows how people joked about it. The good news is that we are going to make a computer vision model in this lesson today. So get excited!"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#before-neural-networks",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#before-neural-networks",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Before Neural Networks",
    "text": "Before Neural Networks\nIn the era before neural networks, people used a lot of workforce to identify images, then many mathematicians and computer scientists to process those images and create separate features for each one of them. After a lot of time and processing, they would fit it into a machine learning model. It became successful, but the problem was that making these models took a lot of time and energy, which was inefficient and tedious."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#the-first-neural-network",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#the-first-neural-network",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "The first neural network",
    "text": "The first neural network\nBack in 1957 a neural network was described as something like a program. So in a traditional program we have some inputs and then we put them in program which have functions, conditionals, loops etc and these give us the result."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#deep-learning-models",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#deep-learning-models",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Deep learning models",
    "text": "Deep learning models\nIn deep learning the program is replaced by Model and we now also have weights(Also called parameters) with inputs. The model is not anymore a bunch of conditionals and loops and things. In case of a neural network it is a mathematical function which takes the inputs, multiplies them together by the weights and adds them up. And it does that will all the sets of inputs. And thus a neural network is formed\nNow a model will not do anything useful unless these weights are carefully chosen, so we start by these weights being random. Initially these networks don’t do anything useful.\nWe then take the inputs and weights put them in our model and get the results. The we decide how good they are, this is done by a number called loss. Loss describe how good the results are, think of it as something like accuracy. After we get loss we use it to update our weights and then repeat this process again and again, we get better and better results.\nOnce we do this enough times we stop putting inputs and weights and replace it with inputs and get some outputs."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#how-modern-neural-networks-work",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#how-modern-neural-networks-work",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "How Modern Neural Networks Work",
    "text": "How Modern Neural Networks Work\nWith modern neural network methods, we don’t teach the model features; we make them learn features. It is done by breaking the image into small parts and assigning them features (often called layer 1 features). After doing this for many images, we combine them to create more advanced features. So we train the basic neural network and make it a more advanced neural network, creating a kind of feature detector that finds the related features.\nCoding these features would be very difficult, and many times you wouldn’t even know what to code. This is how we make neural networks more efficient by not making them by code but by making them learn."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#misconceptions-about-deep-learning",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#misconceptions-about-deep-learning",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Misconceptions About Deep Learning",
    "text": "Misconceptions About Deep Learning\nAs we saw earlier, to train a computer vision model, we didn’t need expensive computers, we didn’t need very high-level math, and we didn’t need lots of data. This is the case with much of deep learning which we will learn. There will be some math that will be needed but mostly, either we will teach you the little bits, or we will refer you to some resources."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#pytorch-vs-tensorflow",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#pytorch-vs-tensorflow",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "PyTorch vs TensorFlow",
    "text": "PyTorch vs TensorFlow\nIn recent years, PyTorch is increasingly used in research while TensorFlow is declining in popularity. The library which is used in research is more likely to be used in industry; therefore, we will be using PyTorch for learning Deep Learning.\nAnother thing to note is that sometimes PyTorch uses a lot of code for some really basic tasks, and this is where fastai comes into play. The operations which are really lengthy to implement in PyTorch can be done with very few lines of code with fastai. This is not because PyTorch is bad but because PyTorch is designed so that many good things can be built on top of it.\nThe problem with having lots of code is that it increases the chances of mistakes. In fastai, the code you don’t write is code that the developers have found best practices for and implemented for you."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#jupyter-notebook",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#jupyter-notebook",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Jupyter Notebook",
    "text": "Jupyter Notebook\nJupyter notebook is a web-based application which is widely used in academia and teaching, and it is a very powerful tool to experiment, explore, and build with.\nNowadays, most people don’t run Jupyter notebooks on their own local machines but on cloud servers. If you go to course.fast.ai, you can see how to use Jupyter and cloud servers. One of the good ones is Kaggle. Kaggle doesn’t only have competitions but also has cloud servers where you can train neural networks. You can learn more about it at https://course.fast.ai/Resources/kaggle.html."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#import-statements",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#import-statements",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Import Statements",
    "text": "Import Statements\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\nimport time\nimport json\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nThese lines import necessary libraries: - DDGS: DuckDuckGo search API for finding images - fastcore: Utility functions for deep learning - fastdownload: For downloading files from URLs - fastai: Deep learning library built on PyTorch - time: For time-related operations\nNote: You might get an error for duckduckgo_search while executing this part. Don’t panic - just go to the console and execute:\npip install duckduckgo-search\nThis will install duckduckgo-search in your notebook."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#image-search-function",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#image-search-function",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Image Search Function",
    "text": "Image Search Function\ndef search_images(keywords, max_images=400):\n    return L(DDGS().images(keywords, max_results=max_images)).itemgot(\"image\")\nThis function: - Takes search keywords and maximum number of images - Uses DuckDuckGo to search for images - Returns a list of image URLs - L() creates a fastai list - itemgot(\"image\") extracts just the image URLs from the search results"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#initial-test-downloads",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#initial-test-downloads",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Initial Test Downloads",
    "text": "Initial Test Downloads\nurls = search_images(\"pedestrians\", max_images=1)\nprint(urls[0])\ndest = \"pedestrians.jpg\"\ndownload_url(urls[0], dest, show_progress=False)\nim = Image.open(dest)\nThis section: - Searches for one pedestrian image - Downloads it as ‘pedestrians.jpg’ - Opens it to verify the download worked\nNow we all know that computers don’t understand images, but the good news is that computers can understand numbers, and all images are made up of pixels which contain information about the brightness of red, green, and blue colors. So every picture is just a collection of numbers representing the amount of red, green, and blue in each pixel.\ndownload_url(\n    search_images(\"Cyclist\", max_images=1)[0], \"cyclist.jpg\", show_progress=False\n)\nImage.open(\"cyclist.jpg\").to_thumb(256, 256)\n\nWe are now downloading the test image\nOur model will predict if this image is an image of cyclists\nCreates a 256x256 thumbnail version"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#dataset-creation",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#dataset-creation",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Dataset Creation",
    "text": "Dataset Creation\nsearches = [\"Cyclists\", \"Pedestrians\"]\npath = Path(\"pedestrians_or_cyclists\")\nfor o in searches:\n    dest = path / o\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f\"{o} photo\"))\n    time.sleep(5)\n    resize_images(path / o, max_size=400, dest=path / o)\nThis loop: - Creates directories for each category - Downloads multiple images for each category - Adds “photo” to search terms for better results - Waits 5 seconds between searches to be polite to the search API - Resizes all images to a maximum size of 400 pixels"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#image-verification",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#image-verification",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Image Verification",
    "text": "Image Verification\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\nThese lines: - Check all downloaded images for corruption - Delete any corrupt images - Count how many images were removed"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#dataloader-creation",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#dataloader-creation",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "DataLoader Creation",
    "text": "DataLoader Creation\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method=\"squish\")],\n).dataloaders(path, bs=10)\nThis creates a FastAI DataBlock with: - Image inputs and category labels - 80/20 train/validation split - Directory names as labels - Images resized to 192x192 - Batch size of 10 (Number of images shown to check the data)\nLet’s discuss these one by one:\nThe first thing that we tell fastai is what kind of input we have. This is defined by blocks. Here the input is Image, therefore we set blocks to ImageBlock. To find all the inputs to our model, we run get_image_files (function which returns all image files in a path).\nWe used the same function earlier to remove all the corrupted images.\nNow it is important to put aside some data to test the accuracy of our model. It is so critical to do so that fastai won’t let you train a model without that information. How much data is going to be set aside is determined by RandomSplitter. (In our case, we are randomly setting aside 20% of data for our validation set).\nNext, we tell fastai the way to know the correct label of the photo. We do this with the get_y function. This function tells it to take the label of the photo from its parent directory (the directory in which the photo is stored).\nAll computer vision architectures need all of the input to be the same size. By using item_tfms, we are resizing every image to be (192,192) each, and the method of resize is going to be ‘squish’. You can also crop it from the middle.\nWith the help of dataloaders, PyTorch can grab a lot of your data at one time, and this is done quickly using a GPU which can do a thousand things at once. So dataloader will feed the image model with a lot of data that is provided to it at once. We call these images a batch.\nbs=10 will show 10 images from the data it is feeding to the algorithm with labels.\nNote: You can learn more about these functions by going to the tutorials and documentation of fastai."
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#model-training",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#model-training",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Model Training",
    "text": "Model Training\nHere we will train our model with resnet18. In fastai, a learner is something which combines our neural net and the data we train it with.\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\nThese lines: - Create a vision model using ResNet18 architecture. It’s like creating a baby AI, except it won’t keep you up at night (your debugging sessions will do that instead). - Fine-tune it for 3 epochs - Track error rate as the metric\nIt will usually take about a minute or two if you use only CPU, but it can take about 10 seconds if you train it on GPU. This difference is because someone has already trained it (pretraining) to recognize over 14 Million images over 20,000 different types, something called the ImageNet dataset. So you actually start with a network which can do a lot, and they made all these parameters available to download from the internet.\nlearn.fine_tune takes those pre-trained weights and adjusts them to teach the model the differences between your datasets and what it was originally trained for. This method is called fine tuning.\nYou can get different architectures from https://timm.fast.ai/"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#prediction",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#prediction",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Prediction",
    "text": "Prediction\nis_cyclist, _, probs = learn.predict(PILImage.create('cyclist.jpg'))\nprint(f\"This is a: {is_cyclist}.\")\nprint(f\"Probability that it is cyclist: {probs[0]:f}\")\nFinally: - Loads and predicts on a test image - Prints the predicted class - Shows the probability of the prediction"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#tabular-analysis",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#tabular-analysis",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Tabular Analysis",
    "text": "Tabular Analysis\nWe can also can help analyze structured data like spreadsheets. Let’s start by breaking down each line of code and understanding what it does:\nfrom fastai.tabular.all import *\nThis line imports all the necessary functions and classes from fastai’s tabular module.\npath = untar_data(URLs.ADULT_SAMPLE)\nHere, we’re downloading and extracting a sample dataset called “Adult” that predicts whether someone makes over $50K per year. The untar_data function: - Downloads the dataset if it’s not already present - Extracts it from its compressed format - Returns the path where the data is stored\ndls = TabularDataLoaders.from_csv(\n    path/'adult.csv',\n    path=path,\n    y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status',\n                 'occupation', 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize]\n)\nThis is where the magic begins! Let’s break this down: - We’re creating a DataLoader object that handles how we feed data to our model - path/'adult.csv': Specifies the CSV file containing our data - y_names=\"salary\": Indicates that “salary” is our target variable (what we’re trying to predict) - cat_names: Lists our categorical columns (text or discrete data) like workclass, education etc - cont_names: Lists our continuous numerical columns like age, final weight(a census data concept) , education num(numerical encoding of education level). These are the columns which can take any real number - procs: Specifies the preprocessing steps: - Categorify: Converts categorical variables into numbers - FillMissing: Handles any missing values - Normalize: Scales numerical data to a similar range\nlearn = tabular_learner(dls, metrics=accuracy)\nThis line creates our machine learning model: - tabular_learner: Creates a neural network designed for tabular data - metrics=accuracy: Tells the model to track prediction accuracy during training\ndls.show_batch()\nThis displays a sample of our processed data, helping us verify that everything looks correct before training. The beautiful thing about this function is that it uses type dispatch which is particularly used in a language called julia and it allows us to define functions that can adapt their behavior according to input types. Basically it will provide realistic data for age, fnlwgt etc\nlearn.fit_one_cycle(2)\nFinally, we train our model: - We don’t say fine tune model because for tables because every table of data is very different. So we just ‘fit’ the data. - The number 2 indicates we’ll train for 2 epochs (full passes through the data) - “one_cycle” refers to the One Cycle Policy, a training technique that helps achieve better results faster\n\nWhy Tabular Deep Learning?\nYou might wonder why we’d use deep learning for tabular data when we have traditional methods like Random Forests or XGBoost. Here’s why:\nIt can help in financial predictions, risk assesment, sales forcasting etc"
  },
  {
    "objectID": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#collaborative-filtering",
    "href": "posts/Lesson-1-Making-a-Cyclist-recogniser.html#collaborative-filtering",
    "title": "Lesson 1: Vision models and Fundamentals",
    "section": "Collaborative Filtering",
    "text": "Collaborative Filtering\nCollaborative filtering is the basis of most recommandation systems today. From your youtube recommandation to the recommandations you see in spotify.\nIt works by finding which users liked which products and then it use that to guess what other product smilar user liked and based on those smilar users what users might like.\nNote that here Similar Users don’t mean similar demographically but similar in sense that those people liked the same kind of product that you liked.\n\n1. Import the necessary modules:\nfrom fastai.collab import *\n\nThis imports everything from the fastai.collab module, which provides tools for collaborative filtering and recommendation systems.\n\n\n\n2. Download and extract sample data:\npath = untar_data(URLs.ML_SAMPLE)\n\nAgain we are downloading and extracting data here\nURLs.ML_SAMPLE points to a small sample dataset from the MovieLens dataset, commonly used in recommendation system experiments.\n\n\n\n3. Create data loaders for collaborative filtering:\ndls = CollabDataLoaders.from_csv(path/'ratings.csv')\n\nCollabDataLoaders.from_csv reads a CSV file containing user-item interaction data (e.g., user ratings for movies) to create a data loader.\npath/'ratings.csv' specifies the path to the CSV file that contains the ratings dataset.\nThe dls object now holds the data loaders, which manage the data used for training and validation during the model’s training process.\n\n\n\n4. Display a sample batch of data:\ndls.show_batch()\n\nThis displays a sample batch of user-item-rating triplets (e.g., a user ID, a movie ID, and the user’s rating for the movie).\n\n\n\n5. Create a collaborative filtering model:\nlearn = collab_learner(dls, y_range=(0.5,5.5))\n\ncollab_learner initializes a collaborative filtering model based on a neural network architecture.\nThe dls object is passed to define the input data.\ny_range=(0.5, 5.5) specifies the range of the target values (ratings), helping the model output predictions in the expected range.\n\n\n\n6. Train the model with fine-tuning:\nlearn.fine_tune(10)\n\nfine_tune trains the model for a specified number of epochs—in this case, 10 epochs.\nThe model first uses a pre-trained embedding (if available) and then fine-tunes it on the given dataset.\n\n\n\n7. Display the results:\nlearn.show_results()\n\nThis method shows the predictions made by the model alongside the actual ratings from the test dataset.\nIt provides an intuitive way to evaluate the model’s performance by comparing predicted and actual ratings."
  },
  {
    "objectID": "posts/Installing-Dependencies.html",
    "href": "posts/Installing-Dependencies.html",
    "title": "How to setup WSL and Python for fastAI",
    "section": "",
    "text": "WSL implies for Windows Subsystem for Linux (WSL), where you can run a Linux environment on your Windows machine without the hassle of dual-booting or setting up a virtual machine. This guide will take you through the steps to install WSL, focusing on WSL 2, which is faster, better, and more compatible than its predecessor.\nThe basic prerequisits are that You need Windows 10 version 2004 or higher (Build 19041 and above) or Windows 11. If you’re still rocking an older version, it might be time for an upgrade—like swapping out your flip phone for a smartphone!\nIf you get any error related to virtualization. You need to have virtualization enabled which you can do by enabling Hyper V in your device\n\n\nOpen PowerShell as Administrator: Search for “PowerShell” in the Start menu. Right-click on it and select “Run as administrator”. If you get intimidated by the black screen don’t panik you are inside terminal which helps us to execute commands. More on it later! Run the Installation Command: In the PowerShell window, type the following command and press Enter\nwsl --install\nThis command will enable all the necessary features for WSL, download the Linux Kernel, and install Ubuntu as your default distribution. A restart may be required.\nIf ubuntu is not your cup of tea then you can choose another distribution by\nwsl --install -d Debian\nfor debian\n\n\n\nAfter installation, launch your installed Linux distribution from the Start menu\nYou’ll be prompted to create a username and password. Choose wisely this is your secret identity! Remember, while typing your password, nothing will appear on the screen; this is normal behavior in Linux. It’s not broken; it’s just shy.\n\n\n\nNow that you’ve got your Linux environment set up, let’s make sure it’s up to date: you can do that by just typing\nsudo apt update\nsudo apt upgrade"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-1-enable-wsl",
    "href": "posts/Installing-Dependencies.html#step-1-enable-wsl",
    "title": "How to setup WSL and Python for fastAI",
    "section": "",
    "text": "Open PowerShell as Administrator: Search for “PowerShell” in the Start menu. Right-click on it and select “Run as administrator”. If you get intimidated by the black screen don’t panik you are inside terminal which helps us to execute commands. More on it later! Run the Installation Command: In the PowerShell window, type the following command and press Enter\nwsl --install\nThis command will enable all the necessary features for WSL, download the Linux Kernel, and install Ubuntu as your default distribution. A restart may be required.\nIf ubuntu is not your cup of tea then you can choose another distribution by\nwsl --install -d Debian\nfor debian"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-2-make-a-user-account",
    "href": "posts/Installing-Dependencies.html#step-2-make-a-user-account",
    "title": "How to setup WSL and Python for fastAI",
    "section": "",
    "text": "After installation, launch your installed Linux distribution from the Start menu\nYou’ll be prompted to create a username and password. Choose wisely this is your secret identity! Remember, while typing your password, nothing will appear on the screen; this is normal behavior in Linux. It’s not broken; it’s just shy."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-4-update-the-system",
    "href": "posts/Installing-Dependencies.html#step-4-update-the-system",
    "title": "How to setup WSL and Python for fastAI",
    "section": "",
    "text": "Now that you’ve got your Linux environment set up, let’s make sure it’s up to date: you can do that by just typing\nsudo apt update\nsudo apt upgrade"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#some-basic-definitions-and-tools-handy-in-cli",
    "href": "posts/Installing-Dependencies.html#some-basic-definitions-and-tools-handy-in-cli",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Some basic definitions and tools handy in cli",
    "text": "Some basic definitions and tools handy in cli\nSo here are some popular commands and definitions which we need to keep in mind while we use CLI\ndirectory - for most cases directory is your ‘folder’ we can store different files and directories in a directory.\nls : Lists the contents of a directory. Use options like -a for hidden files or -l for detailed information.\ncd [directory]: Changes the current directory to the specified one. Use cd .. to go back\nmkdir [dirname]: Creates a new directory with the specified name.\nrm -rf [dirname] : Removes a directory and everything in it. This is done without confirmation so know what you are doing"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-1-install-wget-in-you-system",
    "href": "posts/Installing-Dependencies.html#step-1-install-wget-in-you-system",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 1: Install wget in you system",
    "text": "Step 1: Install wget in you system\nyou can do so by executing -\nsudo apt install wget"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-2-download-the-setup-script-for-miniforge",
    "href": "posts/Installing-Dependencies.html#step-2-download-the-setup-script-for-miniforge",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 2: Download the setup script for miniforge",
    "text": "Step 2: Download the setup script for miniforge\nyou can do that by following these commands\n\nfor x86_64\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n\nfor arm\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-aarch64.sh\nthis will download the Miniforge installer in your WSL"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-3-install-miniforge-in-your-wsl",
    "href": "posts/Installing-Dependencies.html#step-3-install-miniforge-in-your-wsl",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 3: Install miniforge in your WSL",
    "text": "Step 3: Install miniforge in your WSL\nexecute the following command -\n\nFor x86_64\nbash Miniforge3-Linux-x86_64.sh\n\n\nFor Arm\nbash Miniforge3-Linux-aarch64.sh\nA simple setup will appear which will ask you to accept the licence agreement\nThen a prompt will appear telling you that setup will install miniforge in your home directory say yes to it\nAnd then miniforge will install not only python but a whole bunch of libraries which will come handy to us later.\nrestart you shell by executing bash to make it initialize miniforge"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-4-agree-to-initialize-it",
    "href": "posts/Installing-Dependencies.html#step-4-agree-to-initialize-it",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 4: Agree to initialize it",
    "text": "Step 4: Agree to initialize it\nIt will ask you if you want to initialize it whenever you start your machine and say yes to it.\nWhat it will do is that it will execute python everytime we launch wsl"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#mamba-and-conda",
    "href": "posts/Installing-Dependencies.html#mamba-and-conda",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Mamba and conda",
    "text": "Mamba and conda\nMamba and Conda are both powerful tools used for package and environment management in Python. They install everything we need for python and help us create virtual environments. This brings us to - ## Step 5: Enable virtual environment\nA virtual environment is a self-contained directory that allows you to manage dependencies for different projects without stepping on each other’s toes. It will help seperate python we need with the system python\nTo create a virtual environment just execute:\nmamba create -n fastai_env python=3.9\nthis will create a python virtual environment\nbut that’s not all we also need to activate it for it to work this is done by executing\nmamba activate fastai_env\n\nA pro tip - You can activate the virtual environment everytime you want by putting it in your .bashrc file. You can do that by\n\nnano .bashrc\nthis opens a text editor which we will use to edit files. Edit it by adding mamba activate fastai_env at the end of the file.\nthen press ctrl + x to exit and y to save the file."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-6-installing-ipython-and-jupyter-lab",
    "href": "posts/Installing-Dependencies.html#step-6-installing-ipython-and-jupyter-lab",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 6: Installing ipython and jupyter lab",
    "text": "Step 6: Installing ipython and jupyter lab\n\nNeed for these tools\nIf you’re ready to kick your AI game up a notch, you need to get cozy with IPython, JupyterLab, nbdev. We have so many good reasons to use these tools\nWe will use Ipython because\n\nIt helps us to display media like Images, Videos etc\nIPython includes special commands (prefixed with % or %%) that allow you to perform tasks like timing execution or running shell commands seamlessly.\nWith improved tracebacks and debugging capabilities, it makes troubleshooting easier.\n\nWe will use Jupyter Lab because -\n\nMulti document UI - Open multiple notebooks, text files, and terminals all at once. You can juggle your projects too. No more switching tabs.\nExtensions Galore: Want to customize your experience? JupyterLab supports extensions that let you add new features or integrate with other tools. It’s like dressing up your notebook in the latest fashion make it yours\nInteractive Widgets: Create interactive visualizations and controls right in your notebooks. Want to tweak parameters on the fly? Just slide those sliders.\n\nnbdev is Important because\n\nLiterate Programming: Write code, tests, and documentation together in Jupyter notebooks, enhancing readability and maintainability.\nAutomatic Documentation: Generate up-to-date documentation directly from your notebooks, streamlining the process of creating and maintaining libraries.\nIntegrated Testing: Write and run unit tests within your notebooks, ensuring code quality with automatic execution during builds and CI/CD processes.\n\nBasically they help is making the experiance smoother for the journey. ### Installation\nHere is the command to install these tools -\nmamba install ipython jupyterlab nbdev"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-7-install-pytorch",
    "href": "posts/Installing-Dependencies.html#step-7-install-pytorch",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 7: Install pytorch",
    "text": "Step 7: Install pytorch\nPyTorch is a powerful and flexible tool for deep learning and machine learning projects. Here are some of its features\n\nDynamic Computation Graphs: Allows changes to the model on-the-fly, making debugging easier.\nTensor Operations: Supports efficient tensor computations with GPU acceleration for faster processing.\nUser-Friendly: Intuitive and Pythonic interface, great for beginners and experienced users alike.\nRich Ecosystem: Includes libraries for building neural networks and optimization, simplifying model development.\nStrong Community: Extensive documentation and active community support for learning and troubleshooting.\n\n\nInstallation\nHere is how to get it installed -\n\nFor devices with Nvidia GPU - if your device have an Nvidia GPU then you can install pytorch with CUDA support by executing following command -\n\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\nYou will also need to install the cuda toolkit for pytorch to work. You can do it by executing -\n\nwget https://developer.download.nvidia.com/compute/cuda/12.6.2/local_installers/cuda_12.6.2_560.35.03_linux.run\nThen run\nsudo sh cuda_12.6.2_560.35.03_linux.run\n\nFor devices with integrated graphics - If you are poor student like me and have device with integrated graphics then you should install pytorch by using following command -\n\nmamba install pytorch torchvision torchaudio cpuonly -c pytorch"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-8-install-fastai",
    "href": "posts/Installing-Dependencies.html#step-8-install-fastai",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Step 8: Install FastAI",
    "text": "Step 8: Install FastAI\nFast AI will be the main library we will be working with. It is designed to make deep learning accessible to everyone, regardless of their coding experience. It is is built on top of PyTorch designed to make the complex realm of artificial intelligence as approachable as your favorite recipe for instant noodles.\n\nInstallation\nTo install it just execute this command in your terminal -\nmamba install -c fastai fastai\nAnd you have successfully installed the tools required for the course."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#vim",
    "href": "posts/Installing-Dependencies.html#vim",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Vim",
    "text": "Vim\nVim is the most supereme cli text editor that one can use in linux. Here is how to install and use it\n\nOpen WSL Terminal:\n\nLaunch your WSL terminal.\n\nUpdate Package List:\n\nBefore installing any software, update the package list by running:\nsudo apt update\n\nInstall Vim:\n\nInstall Vim by executing the following command:\nsudo apt install vim -y\nThis command retrieves and installs Vim along with its necessary components.\n\nLaunching Vim:\n\nTo create or edit a file, use the command:\nvim filename.txt\nReplace filename.txt with your desired file name. If the file does not exist, Vim will create it.\n\nBasic Navigation and Editing:\n\nUpon opening a file, you start in Normal mode. Press i to switch to Insert mode, where you can type text.\nTo return to Normal mode, press Esc.\nYou can go up down left and right in the document by either using arrow keys or using h,j,k,l keys (right,down,up,left).\n\nSaving and Exiting:\n\nTo save changes, type :w and press Enter.\nTo exit Vim, type :q and press Enter. If you want to save and exit simultaneously, type :wq."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#ranger",
    "href": "posts/Installing-Dependencies.html#ranger",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Ranger",
    "text": "Ranger\nRanger is a cli file manager which you can use to navigate through files easily.\nTo install and use Ranger, a VIM-inspired file manager, in Windows Subsystem for Linux (WSL), follow these detailed steps:"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#installation-steps",
    "href": "posts/Installing-Dependencies.html#installation-steps",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Installation Steps",
    "text": "Installation Steps\n\nOpen WSL Terminal:\n\nLaunch your WSL terminal\n\nInstall Prerequisites:\n\nUpdate the package list and install the necessary packages (make, git, and vim) by running:\nsudo apt update\nsudo apt install make git vim -y\n\nInstall Ranger:\nsudo apt install ranger -y\nConfigure Ranger:\n\nRun Ranger once to create the configuration directory:\nranger"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#using-ranger",
    "href": "posts/Installing-Dependencies.html#using-ranger",
    "title": "How to setup WSL and Python for fastAI",
    "section": "Using Ranger",
    "text": "Using Ranger\n\nLaunching Ranger:\n\nStart Ranger by typing:\nranger\n\nInterface Overview:\n\nThe interface is divided into three columns:\n\nLeft Column: Displays the parent directory.\nMiddle Column: Shows contents of the current directory.\nRight Column: Provides a preview of the selected file or folder.\n\n\nBasic Navigation:\n\nUse the following keys to navigate:\n\nArrow keys or h, j, k, l for left, down, up, and right respectively.\nEnter to open a file or directory.\nq to quit.\n\n\n\n\nCopying, Pasting, and Deleting Files\n\nCopying Files:\n\nTo copy a file or directory, navigate to it and press yy (yank).\nTo copy multiple files, select them using Space and then press yy.\n\nPasting Files:\n\nNavigate to the destination directory and press p to paste the copied files.\n\nDeleting Files:\n\nTo delete a file or directory, navigate to it and press dd (delete).\nConfirm the deletion when prompted."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this blog is to create a place where fastAI learners can come and follow along while watching the lecture"
  }
]